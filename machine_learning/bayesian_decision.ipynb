{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from patsy import dmatrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('lahman-csv_2015-01-24/Batting.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.query('AB > 100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.query('yearID > 1950')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    22257.000000\n",
       "mean        92.346138\n",
       "std         49.408129\n",
       "min          6.000000\n",
       "25%         48.000000\n",
       "50%         86.000000\n",
       "75%        133.000000\n",
       "max        262.000000\n",
       "Name: H, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.H.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make it possible for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wsorenson/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "df['manyhits'] = df.H.apply(lambda x: x > 133)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Decision Trees "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"QRTFJEGM1U5W7K62MIBVGW9N05S73A0T.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabilistic Decision Trees uses probabilities. Error bars from Bayesian Theory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used often in computational biology and bioinformatics. This is basically the same concept as PyMC. \n",
    "\n",
    "$$ x_{i}\\sim N(\\theta _{i},\\sigma ^{2}),\n",
    "{\\displaystyle \\theta _{i}\\sim N(\\varphi ,\\tau ^{2})} \\theta _{i}\\sim N(\\varphi ,\\tau ^{2})$$\n",
    "\n",
    "[link](https://en.wikipedia.org/wiki/Bayesian_network). Formally Bayesian Networks are DAGs whose notes represent random variables. They can be latent variables, observable quantities, unknown parameters, or hypothesis. \n",
    "\n",
    "- **Input** Particular set values for the node's parent variables\n",
    "- **Edges** represent conditional depenencies; note sthat aren't connected epresent variables that are *conditionally independent of eachother* \n",
    "- **Nodes** Represent variables in a bayesian sense \n",
    "- **Output** the probability of the variable represneted in the node. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"PKAWFRJLCX0Y2IC4G525RJA3OFY67XWJ.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to know what the chances are that it is raining given the grass is wet, we can do the following formulation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\mathrm {P} ({\\mathit {R}}=T\\mid {\\mathit {G}}=T)={\\frac {\\mathrm {P} ({\\mathit {G}}=T,{\\mathit {R}}=T)}{\\mathrm {P} ({\\mathit {G}}=T)}}={\\frac {\\sum _{{\\mathit {S}}\\in \\{T,F\\}}\\mathrm {P} ({\\mathit {G}}=T,{\\mathit {S}},{\\mathit {R}}=T)}{\\sum _{{\\mathit {S}},{\\mathit {R}}\\in \\{T,F\\}}\\mathrm {P} ({\\mathit {G}}=T,{\\mathit {S}},{\\mathit {R}})}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general idea here is that we sum over the nuistance variable (Sprinkler).\n",
    "\n",
    "A major advantage of Bayesian networks is that it can save considerable amounts of memory. Storing conditional probabilities of 10 two-valued variables as a table requires storage space for 2^10 values. Bayesian network requires storage of at most 10 * 2^3 values. \n",
    "\n",
    "It is also easier to interpret than sparse joint probabilities. \n",
    "\n",
    "It can also be useful the snetwork is too complex for humans. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Markov Property"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This satisfied the **local markov property** that each variable is conditionally independent of its non-descendents given its parent value. \n",
    "\n",
    "$X_{v}\\perp \\!\\!\\!\\perp X_{V\\setminus \\operatorname {de} (v)}\\mid X_{\\operatorname {pa} (v)}\\quad {\\text{for all }}v\\in V$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Net Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[link](http://www.cs.ubc.ca/~murphyk/Bayes/bnintro.html). \n",
    "\n",
    "- One reason this is caled generative is because we can generate all of the probabilities from any starting point. \n",
    "- It is also possible to create bayesian networks with continous valued nodes (e.g., Gaussian, softmax). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dynamic Bayesian Networks are Directed graphical models of stochastic processes. Generalize HMM by representing latent state in terms of state variables. **Temporal** would be a better name since we assume that the model structure doesn't change. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplist kind of DBN is an HMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"CU9D5KNJORNQXL8RJQX3H3G5OBJM9QQE.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"JRE4MYCNKCSR0ERPL9JPLUEJCCFT80YX.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X — states\n",
    "y — possible observations\n",
    "a — state transition probabilities\n",
    "b — output probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A key idea is that push sums in to get rid of irrelevant terms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The running time of DP algorithms is exponential in size of the largest cluster. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximation Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since many models have a large structure, we need to result to Approximation Methods. These can be:\n",
    "\n",
    "Monte Carlo Methods or other ideas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Field Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another form of approximation is the mean field theory. The basic idea is to make a simple model from a complex, stochastic one. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
